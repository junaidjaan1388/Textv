name: Deploy Text-to-Video Generator

on:
  push:
    branches: [ main ]

jobs:
  deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg libsm6 libxext6

    - name: Clone and setup LTX Video
      run: |
        git clone https://huggingface.co/spaces/Jaan15/ltx-video-distilled
        cd ltx-video-distilled
        
        # Create virtual environment
        python -m venv env
        source env/bin/activate
        
        # Upgrade pip and install dependencies
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Set up Hugging Face token (for private models)
      working-directory: ./ltx-video-distilled
      env:
        HUGGINGFACE_HUB_TOKEN: ${{ secrets.HUGGINGFACE_HUB_TOKEN }}
      run: |
        source env/bin/activate
        # If models are private, set up token
        if [ -n "$HUGGINGFACE_HUB_TOKEN" ]; then
          huggingface-cli login --token $HUGGINGFACE_HUB_TOKEN --add-to-git-credentials
        fi

    - name: Pre-download models (with error handling)
      working-directory: ./ltx-video-distilled
      run: |
        source env/bin/activate
        python -c "
import os
os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'

try:
    from huggingface_hub import hf_hub_download, snapshot_download
    import torch
    
    print('Starting model download...')
    
    # Try to download the main model with error handling
    try:
        model_path = hf_hub_download(
            repo_id='Jaan15/ltx-video-distilled',
            filename='pytorch_model.bin',
            cache_dir='./models',
            resume_download=True
        )
        print(f'✓ Model downloaded: {model_path}')
    except Exception as e:
        print(f'⚠ Model download failed: {e}')
        print('Trying alternative download method...')
        
        # Alternative: Try snapshot download
        try:
            snapshot_path = snapshot_download(
                repo_id='Jaan15/ltx-video-distilled',
                cache_dir='./models',
                resume_download=True
            )
            print(f'✓ Snapshot downloaded: {snapshot_path}')
        except Exception as e2:
            print(f'✗ Alternative download also failed: {e2}')
    
    print('Model preparation completed')
    
except Exception as e:
    print(f'✗ Setup failed: {e}')
    exit(1)
"

    - name: Create modified app.py with error handling
      working-directory: ./ltx-video-distilled
      run: |
        source env/bin/activate
        cat > app_modified.py << 'EOF'
import os
import sys
import logging
import gradio as gr
from huggingface_hub import hf_hub_download
import torch

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Disable symlink warnings
os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'

def setup_models():
    """Setup models with proper error handling"""
    try:
        logger.info("Setting up models...")
        
        # Try to download or locate the model
        try:
            model_path = hf_hub_download(
                repo_id='Jaan15/ltx-video-distilled',
                filename='pytorch_model.bin',
                cache_dir='./models',
                resume_download=True
            )
            logger.info(f"Model found at: {model_path}")
        except Exception as e:
            logger.warning(f"Model download failed: {e}")
            # Check if model exists in cache
            model_path = None
            possible_paths = [
                './models/models--Jaan15--ltx-video-distilled/snapshots/*/pytorch_model.bin',
                './pytorch_model.bin',
                'pytorch_model.bin'
            ]
            
            for path in possible_paths:
                if os.path.exists(path.replace('*', os.listdir('./models/models--Jaan15--ltx-video-distilled/snapshots/')[0] if os.path.exists('./models/models--Jaan15--ltx-video-distilled/snapshots/') else '')):
                    model_path = path
                    break
            
            if not model_path:
                raise Exception("Could not locate model file")
        
        return model_path
        
    except Exception as e:
        logger.error(f"Model setup failed: {e}")
        return None

def text_to_video(prompt):
    """Text to video generation with error handling"""
    try:
        # Your video generation logic here
        # This is a placeholder - replace with actual implementation
        
        logger.info(f"Generating video for prompt: {prompt}")
        
        # Check if models are available
        model_path = setup_models()
        if not model_path:
            return None, "Error: Models not available. Please check the setup."
        
        # Simulate video generation (replace with actual code)
        # For now, return a placeholder
        return "sample_video.mp4", f"Video generated for: {prompt}"
        
    except Exception as e:
        logger.error(f"Video generation failed: {e}")
        return None, f"Error: {str(e)}"

# Create Gradio interface
with gr.Blocks() as demo:
    gr.Markdown("# Text-to-Video Generator")
    gr.Markdown("Enter a text prompt to generate a video")
    
    with gr.Row():
        prompt_input = gr.Textbox(
            label="Enter your prompt",
            placeholder="Describe the video you want to generate...",
            lines=2
        )
    
    with gr.Row():
        generate_btn = gr.Button("Generate Video")
    
    with gr.Row():
        video_output = gr.Video(label="Generated Video")
        status_output = gr.Textbox(label="Status", interactive=False)
    
    generate_btn.click(
        fn=text_to_video,
        inputs=[prompt_input],
        outputs=[video_output, status_output]
    )

if __name__ == "__main__":
    # Test model setup first
    logger.info("Initializing text-to-video generator...")
    model_status = setup_models()
    
    if model_status:
        logger.info("✓ Models loaded successfully")
        demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
    else:
        logger.error("✗ Failed to load models")
        sys.exit(1)
EOF

    - name: Run text-to-video generator
      working-directory: ./ltx-video-distilled
      run: |
        source env/bin/activate
        echo "Starting text-to-video generator..."
        python app_modified.py
      env:
        HF_HUB_DISABLE_SYMLINKS_WARNING: '1'
        # Add your Hugging Face token if needed
        # HUGGINGFACE_HUB_TOKEN: ${{ secrets.HUGGINGFACE_HUB_TOKEN }}
